{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MLflow's Model Registry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "source": [
    "from mlflow.tracking import MlflowClient\n",
    "\n",
    "\n",
    "MLFLOW_TRACKING_URI = \"sqlite:///mlflow.db\""
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interacting with the MLflow tracking server\n",
    "\n",
    "The `MlflowClient` object allows us to interact with...\n",
    "- an MLflow Tracking Server that creates and manages experiments and runs.\n",
    "- an MLflow Registry Server that creates and manages registered models and model versions. \n",
    "\n",
    "To instantiate it we need to pass a tracking URI and/or a registry URI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "source": [
    "client = MlflowClient(tracking_uri=MLFLOW_TRACKING_URI)\n",
    "\n",
    "client.list_experiments()"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "source": [
    "client.create_experiment(name=\"my-cool-experiment\")"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check the latest versions for the experiment with id `1`..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "source": [
    "from mlflow.entities import ViewType\n",
    "\n",
    "runs = client.search_runs(\n",
    "    experiment_ids='1',\n",
    "    filter_string=\"metrics.rmse < 7\",\n",
    "    run_view_type=ViewType.ACTIVE_ONLY,\n",
    "    max_results=5,\n",
    "    order_by=[\"metrics.rmse ASC\"]\n",
    ")"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "source": [
    "for run in runs:\n",
    "    print(f\"run id: {run.info.run_id}, rmse: {run.data.metrics['rmse']:.4f}\")"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interacting with the Model Registry\n",
    "\n",
    "In this section We will use the `MlflowClient` instance to:\n",
    "\n",
    "1. Register a new version for the experiment `nyc-taxi-regressor`\n",
    "2. Retrieve the latests versions of the model `nyc-taxi-regressor` and check that a new version `4` was created.\n",
    "3. Transition the version `4` to \"Staging\" and adding annotations to it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "source": [
    "import mlflow\n",
    "\n",
    "mlflow.set_tracking_uri(MLFLOW_TRACKING_URI)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "source": [
    "run_id = \"b8904012c84343b5bf8ee72aa8f0f402\"\n",
    "model_uri = f\"runs:/{run_id}/model\"\n",
    "mlflow.register_model(model_uri=model_uri, name=\"nyc-taxi-regressor\")"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "source": [
    "model_name = \"nyc-taxi-regressor\"\n",
    "latest_versions = client.get_latest_versions(name=model_name)\n",
    "\n",
    "for version in latest_versions:\n",
    "    print(f\"version: {version.version}, stage: {version.current_stage}\")"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "source": [
    "model_version = 4\n",
    "new_stage = \"Staging\"\n",
    "client.transition_model_version_stage(\n",
    "    name=model_name,\n",
    "    version=model_version,\n",
    "    stage=new_stage,\n",
    "    archive_existing_versions=False\n",
    ")"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "source": [
    "from datetime import datetime\n",
    "\n",
    "date = datetime.today().date()\n",
    "client.update_model_version(\n",
    "    name=model_name,\n",
    "    version=model_version,\n",
    "    description=f\"The model version {model_version} was transitioned to {new_stage} on {date}\"\n",
    ")"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparing versions and selecting the new \"Production\" model\n",
    "\n",
    "In the last section, we will retrieve models registered in the model registry and compare their performance on an unseen test set. The idea is to simulate the scenario in which a deployment engineer has to interact with the model registry to decide whether to update the model version that is in production or not.\n",
    "\n",
    "These are the steps:\n",
    "\n",
    "1. Load the test dataset, which corresponds to the NYC Green Taxi data from the month of March 2021.\n",
    "2. Download the `DictVectorizer` that was fitted using the training data and saved to MLflow as an artifact, and load it with pickle.\n",
    "3. Preprocess the test set using the `DictVectorizer` so we can properly feed the regressors.\n",
    "4. Make predictions on the test set using the model versions that are currently in the \"Staging\" and \"Production\" stages, and compare their performance.\n",
    "5. Based on the results, update the \"Production\" model version accordingly.\n",
    "\n",
    "\n",
    "**Note: the model registry doesn't actually deploy the model to production when you transition a model to the \"Production\" stage, it just assign a label to that model version. You should complement the registry with some CI/CD code that does the actual deployment.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "def read_dataframe(filename):\n",
    "    df = pd.read_csv(filename)\n",
    "\n",
    "    df.lpep_dropoff_datetime = pd.to_datetime(df.lpep_dropoff_datetime)\n",
    "    df.lpep_pickup_datetime = pd.to_datetime(df.lpep_pickup_datetime)\n",
    "\n",
    "    df['duration'] = df.lpep_dropoff_datetime - df.lpep_pickup_datetime\n",
    "    df.duration = df.duration.apply(lambda td: td.total_seconds() / 60)\n",
    "\n",
    "    df = df[(df.duration >= 1) & (df.duration <= 60)]\n",
    "\n",
    "    categorical = ['PULocationID', 'DOLocationID']\n",
    "    df[categorical] = df[categorical].astype(str)\n",
    "    \n",
    "    return df\n",
    "\n",
    "\n",
    "def preprocess(df, dv):\n",
    "    df['PU_DO'] = df['PULocationID'] + '_' + df['DOLocationID']\n",
    "    categorical = ['PU_DO']\n",
    "    numerical = ['trip_distance']\n",
    "    train_dicts = df[categorical + numerical].to_dict(orient='records')\n",
    "    return dv.transform(train_dicts)\n",
    "\n",
    "\n",
    "def test_model(name, stage, X_test, y_test):\n",
    "    model = mlflow.pyfunc.load_model(f\"models:/{name}/{stage}\")\n",
    "    y_pred = model.predict(X_test)\n",
    "    return {\"rmse\": mean_squared_error(y_test, y_pred, squared=False)}"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "source": [
    "df = read_dataframe(\"data/green_tripdata_2021-03.csv\")"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "source": [
    "client.download_artifacts(run_id=run_id, path='preprocessor', dst_path='.')"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "source": [
    "import pickle\n",
    "\n",
    "with open(\"preprocessor/preprocessor.b\", \"rb\") as f_in:\n",
    "    dv = pickle.load(f_in)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "source": [
    "X_test = preprocess(df, dv)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "source": [
    "target = \"duration\"\n",
    "y_test = df[target].values"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "source": [
    "%time test_model(name=model_name, stage=\"Production\", X_test=X_test, y_test=y_test)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "source": [
    "%time test_model(name=model_name, stage=\"Staging\", X_test=X_test, y_test=y_test)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "source": [
    "client.transition_model_version_stage(\n",
    "    name=model_name,\n",
    "    version=4,\n",
    "    stage=\"Production\",\n",
    "    archive_existing_versions=True\n",
    ")"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [],
   "outputs": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "0848c9d6c7d415ad6c477ff7ff8e98694d1a4aa96d0deee89244642e6b630036"
  },
  "kernelspec": {
   "display_name": "Python 3.9.12 ('exp-tracking-env')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
