{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Three ways to deploy ML models\n",
    "\n",
    "1. Batch(Offline deployment)\n",
    "2. Web Service\n",
    "3. Streaming\n",
    "\n",
    "2 and 3 are online deployments.\n",
    "\n",
    "* Batch deployment: at certain interval times, the service takes the model and run prediction. E.g. every 1 hour, every 6 hours, every day etc. Example: Predict if certain user is about to churn from the product.\n",
    "* Web Service: Up and running all the time, 1 <> 1 server and client relationship. Whenever the clent sents request, the service makes a prediction. E.g. Predict the duration of the ride, when someone request a ride service on uber.\n",
    "* Streaming: Up and running all the time, but 1 <> many server and client relationship without explicit connection. E.g. once the ride starts, the service triggers multiple predictions: tip prediction, more accurate prediction. 2nd E.g. A user uploaded a youtube video, it predicts \"NSFW\" result, copy right result, then based on multiple prediction it decides it the video should be removed.\n"
   ],
   "id": "525ffca73491210"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Web Service (Deploy with Flask and Docker)\n",
    "https://youtu.be/D7wfMAdgdF8?si=G6e2MyeKMsgJbYB1\n",
    "\n",
    "1. create a virtual environment including needed packages `pipenv install scikit-learn==1.0.2 flask --python 3.9`, this will generate `Pipfile.lock` and `Pipfile` files in the folder.\n",
    "2. enter the virtual env `pipenv shell`(to exit type `exit` in terminal)\n",
    "3. create a `predict.py` that takes a raw input, process it, then make the model prediction(e.g.https://github.com/DataTalksClub/mlops-zoomcamp/blob/main/04-deployment/web-service/predict.py) It should use flask to wrap the prediction function, then once running `python predict.py` in the command line, a server will be up for use to send requestion from running `python test.py`(https://github.com/DataTalksClub/mlops-zoomcamp/blob/main/04-deployment/web-service/test.py)\n",
    "4. Resolve the flask warning: \"WARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\" Install gunicorn `pipenv install gunicorn`, and install requests as development dependency `pipenv install --dev requests`\n",
    "5. Package the app to a docker container https://github.com/DataTalksClub/mlops-zoomcamp/blob/main/04-deployment/web-service/Dockerfile. \n",
    "6. Run `docker build -t ride-duration-service:v1 .` to build the docker image. `ride-duration-service:v1` is the image name.\n",
    "7. To run the docker image `docker run -it --rm -p 9696:9696 ride-duration-service:v1`. `-it` means running in interactive mode, so we can exit it by `CTRL+C`, `--rm` means we should remove the image after we are done,  `-p 9696:9696` means mapping the port `9696` to the container `9696`. \n",
    "8. Then deploy it to kubernetes: https://github.com/DataTalksClub/machine-learning-zoomcamp/blob/master/10-kubernetes/06-kubernetes-simple-service.md"
   ],
   "id": "6bbb22306ad8a4f4"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "When the port is already in used by another program, run `docker ps` and then `docker kill CONTAINER ID`. If it still happends, `sudo lsof -i :9696` then `kill -9 [PID]`.",
   "id": "773ce0b2c88c3a2a"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    ""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
